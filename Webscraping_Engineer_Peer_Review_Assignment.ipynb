{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://gitlab.com/ibm/skills-network/courses/placeholder101/-/raw/master/labs/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer Review Assignment - Data Engineer - Webscraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **20** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "In this part you will:\n",
    "\n",
    "*   Use webscraping to get bank information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we are going to be using Python and several Python libraries. Some of these libraries might be installed in your lab environment or in SN Labs. Others may need to be installed by you. The cells below will install these libraries when executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 4.2 MB/s             \n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=78b2aba392887c2cba642029c90de1c0d595931a743bcdeed481549430567fac\n",
      "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.10.0 bs4-0.0.1 soupsieve-2.3.1\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['bs4==4.10.0']\n",
      "\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/main/linux-64       [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 528 KB / ?? (1.69 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 528 KB / ?? (1.69 MB/s)\n",
      "pkgs/r/linux-64          [<=>                 ] (00m:00s) \n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 432 KB / ?? (1.40 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 528 KB / ?? (1.69 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 528 KB / ?? (1.69 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 528 KB / ?? (1.69 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/r/noarch            [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 528 KB / ?? (1.69 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Done\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/main/noarch         [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 548 KB / ?? (1.74 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/r/linux-64          [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/r/linux-64          [<=>                 ] (00m:00s) Done\n",
      "pkgs/r/linux-64          [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/linux-64       [<=>               ] (00m:00s) 460 KB / ?? (1.48 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (2.63 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 1 MB / ?? (2.63 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 2 MB / ?? (3.18 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 2 MB / ?? (3.18 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 3 MB / ?? (3.47 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 3 MB / ?? (3.47 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 3 MB / ?? (3.70 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) Done\n",
      "pkgs/main/linux-64       [====================] (00m:00s) Done\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - bs4==4.10.0\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package               Version  Build           Channel                  Size\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + beautifulsoup4 \u001b[00m      4.10.0  pyh06a4308_0    pkgs/main/noarch        85 KB\n",
      "\u001b[32m  + bs4            \u001b[00m      4.10.0  hd3eb1b0_0      pkgs/main/noarch        10 KB\n",
      "\u001b[32m  + soupsieve      \u001b[00m       2.3.1  pyhd3eb1b0_0    pkgs/main/noarch        34 KB\n",
      "\n",
      "  Change:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - certifi        \u001b[00m   2021.10.8  py37h89c1867_1  installed                    \n",
      "\u001b[32m  + certifi        \u001b[00m   2021.10.8  py37h06a4308_0  pkgs/main/linux-64     151 KB\n",
      "\u001b[31m  - openssl        \u001b[00m      1.1.1l  h7f98852_0      installed                    \n",
      "\u001b[32m  + openssl        \u001b[00m      1.1.1l  h7f8727e_0      pkgs/main/linux-64       3 MB\n",
      "\n",
      "  Upgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - ca-certificates\u001b[00m   2021.10.8  ha878542_0      installed                    \n",
      "\u001b[32m  + ca-certificates\u001b[00m  2021.10.26  h06a4308_2      pkgs/main/linux-64     115 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 3 packages\n",
      "  Change: 2 packages\n",
      "  Upgrade: 1 packages\n",
      "\n",
      "  Total download: 3 MB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [>                                        ] (00m:00s)  782.64 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished beautifulsoup4                       (00m:00s)              85 KB    784 KB/s\n",
      "Downloading  [>                                        ] (00m:00s)  782.64 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)  782.64 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)  782.64 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)    1.75 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished ca-certificates                      (00m:00s)             115 KB      1 MB/s\n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished soupsieve                            (00m:00s)              34 KB    306 KB/s\n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [======>                                  ] (00m:00s)        1 / 6\n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [======>                                  ] (00m:00s)        1 / 6\n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [=============>                           ] (00m:00s)        2 / 6\n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [=============>                           ] (00m:00s)        2 / 6\n",
      "Downloading  [==>                                      ] (00m:00s)    2.05 MB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        3 / 6\n",
      "Downloading  [====>                                    ] (00m:00s)    3.03 MB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        3 / 6\n",
      "\u001b[2A\u001b[0KFinished certifi                              (00m:00s)             151 KB      1 MB/s\n",
      "Downloading  [====>                                    ] (00m:00s)    3.03 MB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        3 / 6\n",
      "Downloading  [====>                                    ] (00m:00s)    3.03 MB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        3 / 6\n",
      "Downloading  [====>                                    ] (00m:00s)    3.03 MB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        3 / 6\n",
      "Downloading  [====>                                    ] (00m:00s)    3.03 MB/s\n",
      "Extracting   [===========================>             ] (00m:00s)        4 / 6\n",
      "Downloading  [=====>                                   ] (00m:00s)    2.71 MB/s\n",
      "Extracting   [===========================>             ] (00m:00s)        4 / 6\n",
      "\u001b[2A\u001b[0KFinished bs4                                  (00m:00s)              10 KB     70 KB/s\n",
      "Downloading  [=====>                                   ] (00m:00s)    2.71 MB/s\n",
      "Extracting   [===========================>             ] (00m:00s)        4 / 6\n",
      "Downloading  [=====>                                   ] (00m:00s)    2.71 MB/s\n",
      "Extracting   [===========================>             ] (00m:00s)        4 / 6\n",
      "Downloading  [=====>                                   ] (00m:00s)    2.71 MB/s\n",
      "Extracting   [===========================>             ] (00m:00s)        4 / 6\n",
      "Downloading  [=====>                                   ] (00m:00s)    2.71 MB/s\n",
      "Extracting   [==================================>      ] (00m:00s)        5 / 6\n",
      "Downloading  [=========================================] (00m:00s)   19.33 MB/s\n",
      "Extracting   [==================================>      ] (00m:00s)        5 / 6\n",
      "\u001b[2A\u001b[0KFinished openssl                              (00m:00s)               3 MB     17 MB/s\n",
      "Downloading  [=========================================] (00m:00s)   19.33 MB/s\n",
      "Extracting   [==================================>      ] (00m:00s)        5 / 6\n",
      "Downloading  [=========================================] (00m:00s)   19.33 MB/s\n",
      "Extracting   [==================================>      ] (00m:00s)        5 / 6\n",
      "Downloading  [=========================================] (00m:00s)   19.33 MB/s\n",
      "Extracting   [==================================>      ] (00m:00s)        5 / 6\n",
      "Downloading  [=========================================] (00m:00s)   19.33 MB/s\n",
      "Extracting   [=========================================] (00m:00s)        6 / 6\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Requirement already satisfied: lxml==4.6.4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.6.4)\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['html5lib==1.1']\n",
      "\n",
      "pkgs/main/linux-64       Using cache\n",
      "pkgs/main/noarch         Using cache\n",
      "pkgs/r/linux-64          Using cache\n",
      "pkgs/r/noarch            Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - html5lib==1.1\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package         Version  Build         Channel                 Size\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + html5lib    \u001b[00m      1.1  pyhd3eb1b0_0  pkgs/main/noarch       91 KB\n",
      "\u001b[32m  + webencodings\u001b[00m    0.5.1  py37_1        pkgs/main/linux-64     19 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 2 packages\n",
      "\n",
      "  Total download: 110 KB\n",
      "\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [======>                                  ] (00m:00s)  132.60 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished webencodings                         (00m:00s)              19 KB    132 KB/s\n",
      "Downloading  [======>                                  ] (00m:00s)  132.60 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  132.60 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  132.60 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  132.60 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [======>                                  ] (00m:00s)  121.21 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [======>                                  ] (00m:00s)  121.21 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  654.27 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "\u001b[2A\u001b[0KFinished html5lib                             (00m:00s)              91 KB    542 KB/s\n",
      "Downloading  [=========================================] (00m:00s)  654.27 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  654.27 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  654.27 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  654.27 KB/s\n",
      "Extracting   [=========================================] (00m:00s)        2 / 2\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas\n",
    "!pip install bs4\n",
    "#!pip install requests\n",
    "!mamba install bs4==4.10.0 -y\n",
    "!pip install lxml==4.6.4\n",
    "!mamba install html5lib==1.1 -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import any additional libraries you may need here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data Using Web Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wikipedia webpage [https://en.wikipedia.org/wiki/List_of_largest_banks](https://en.wikipedia.org/wiki/List_of_largest_banks?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0221ENSkillsNetwork23455645-2021-01-01) provides information about largest banks in the world by various parameters. Scrape the data from the table 'By market capitalization' and store it in a JSON file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webpage Contents\n",
    "\n",
    "Gather the contents of the webpage in text format using the `requests` library and assign it to the variable <code>html_data</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "html_data = requests.get(url).text\n",
    "#print(html_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 1</b> Print out the output of the following line, and remember it as it will be a quiz question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of largest banks -\n"
     ]
    }
   ],
   "source": [
    "print(html_data[101:124])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the Data\n",
    "\n",
    "<b> Question 2</b> Using the contents and `beautiful soup` load the data from the `By market capitalization` table into a `pandas` dataframe. The dataframe should have the country `Name` and `Market Cap (US$ Billion)` as column names.  Display the first five rows using head.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using BeautifulSoup parse the contents of the webpage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0         1   2                                                  3   4  \\\n",
      "0  \\n  [Rank\\n]  \\n                                      [Bank name\\n]  \\n   \n",
      "1  \\n     [1\\n]  \\n  [[[<img alt=\"United States\" class=\"thumbborder...  \\n   \n",
      "2  \\n     [2\\n]  \\n  [[[<img alt=\"United States\" class=\"thumbborder...  \\n   \n",
      "3  \\n     [3\\n]  \\n  [[[<img alt=\"China\" class=\"thumbborder\" data-f...  \\n   \n",
      "4  \\n     [4\\n]  \\n  [[[<img alt=\"United States\" class=\"thumbborder...  \\n   \n",
      "\n",
      "                                   5  \n",
      "0  [Market cap, [], (US$ billion)\\n]  \n",
      "1                        [488.470\\n]  \n",
      "2                        [379.250\\n]  \n",
      "3                        [246.500\\n]  \n",
      "4                        [308.013\\n]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/pandas/core/internals/construction.py:540: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "#Replace the dots below\n",
    "soup = BeautifulSoup(html_data, \"html.parser\")\n",
    "tableData = soup.find_all('table')\n",
    "\n",
    "#print(tableData)\n",
    "for index, table in enumerate(tableData):\n",
    "    #find the relevant table\n",
    "    if \"Market cap\" in str(table) and \"US$ billion\" in str(table):\n",
    "        tableRows = table.find_all('tr')\n",
    "        tableDataFrame = pd.DataFrame(tableRows)\n",
    "        print(tableDataFrame.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the `By market capitalization` table into a pandas dataframe. The dataframe should have the country `Name` and `Market Cap (US$ Billion)` as column names. Using the empty dataframe `data` and the given loop extract the necessary data from each row and append it to the empty dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty row\n",
      "              Name Market Cap (US$ Billion)\n",
      "0    United States                488.470\\n\n",
      "1    United States                379.250\\n\n",
      "2            China                246.500\\n\n",
      "3    United States                308.013\\n\n",
      "4            China                257.399\\n\n",
      "..             ...                      ...\n",
      "65           China                 37.993\\n\n",
      "66  United Kingdom                 37.319\\n\n",
      "67       Singapore                 35.128\\n\n",
      "68           Qatar                 33.560\\n\n",
      "69       Indonesia                 33.081\\n\n",
      "\n",
      "[70 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=[\"Name\", \"Market Cap (US$ Billion)\"])\n",
    "for row in soup.find_all('tbody')[3].find_all('tr'):\n",
    "    col = row.find_all('td')\n",
    "    if(len(col) == 0):\n",
    "        print(\"empty row\")\n",
    "        continue\n",
    "    data.loc[len(data)]= [col[1].a.get('title'),col[2].text]\n",
    "    \n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3** Display the first five rows using the `head` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name Market Cap (US$ Billion)\n",
      "0  United States                488.470\\n\n",
      "1  United States                379.250\\n\n",
      "2          China                246.500\\n\n",
      "3  United States                308.013\\n\n",
      "4          China                257.399\\n\n"
     ]
    }
   ],
   "source": [
    "#Write your code here\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "\n",
    "Usually you will Load the `pandas` dataframe created above into a JSON named `bank_market_cap.json` using the `to_json()` function, but this time the data will be sent to another team who will split the data file into two files and inspect it. If you save the data it will interfere with the next part of the assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "import json\n",
    "jsondata = data.to_json(orient='records')\n",
    "with open('bank_market_cap.json', 'w') as output:\n",
    "  json.dump(jsondata, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy, Joseph Santarcangelo and Azim Hirjani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2020-11-25        | 0.1     | Ramesh Sannareddy | Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2020 IBM Corporation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
